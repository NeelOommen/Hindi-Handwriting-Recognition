{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import csv\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater_function(batch):\n",
    "    final_targets = []\n",
    "    new_images = []\n",
    "    for i in range(len(batch)):\n",
    "        #sample is a tuple of an image and its targets\n",
    "        #unpack\n",
    "        targets = batch[i][1]\n",
    "        image = batch[i][0]\n",
    "\n",
    "        new_dict_entry = {}\n",
    "        #process targets\n",
    "        new_dict_entry['boxes'] = torch.tensor(targets['boxes'], device=device)\n",
    "        new_dict_entry['labels'] = torch.tensor(targets['labels'], device=device)\n",
    "\n",
    "        final_targets.append(new_dict_entry)\n",
    "\n",
    "        image = image.to(device)\n",
    "        new_images.append(image)\n",
    "\n",
    "    return (new_images, final_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "training_dataset = RCNNDataset(\n",
    "    annotations='D:\\\\GitHub\\\\Hindi-Handwriting-Recognition\\\\CNN_test_sandbox\\\\Dataset\\\\Local (Training)\\\\annotations.csv',\n",
    "    img_dir='D:\\\\GitHub\\\\Hindi-Handwriting-Recognition\\\\CNN_test_sandbox\\\\Dataset\\\\Local (Training)',\n",
    "    device=device,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, collate_fn=collater_function)\n",
    "\n",
    "testing_dataset = RCNNDataset(\n",
    "    annotations='D:\\\\GitHub\\\\Hindi-Handwriting-Recognition\\\\CNN_test_sandbox\\\\Dataset\\\\Local (Testing)\\\\annotations.csv',\n",
    "    img_dir='D:\\\\GitHub\\\\Hindi-Handwriting-Recognition\\\\CNN_test_sandbox\\\\Dataset\\\\Local (Testing)',\n",
    "    device=device,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=True, collate_fn=collater_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_of_intersection(bb1, bb2):\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    return intersection_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_evaluate(model, device, optimizer, scheduler, epochs, batch_size, training_loader, testing_loader, testing_dataset, overlap_threshold):\n",
    "    n_total_steps = len(training_loader)\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        start = timer()\n",
    "        for i, (images, targets) in enumerate(training_loader):\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            loss_accumulated = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            loss_value = loss_accumulated.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_accumulated.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        end = timer()\n",
    "        print(f'Time for Epoch {epoch+1}: {end-start:.4f} seconds, loss:{loss_value}')\n",
    "\n",
    "    #Evaluate\n",
    "    print('Evaluating')\n",
    "    model.eval()\n",
    "\n",
    "    #tracking variables\n",
    "    possible_bounding_boxes = 0\n",
    "    correct_bounding_boxes = 0\n",
    "\n",
    "    possible_labels = 0\n",
    "    correct_labels = 0\n",
    "\n",
    "    avg_score = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(testing_loader):\n",
    "            outputs = model(images)\n",
    "            for output in outputs:\n",
    "              boxes = output['boxes'].tolist()\n",
    "              labels = output['labels'].tolist()\n",
    "              score = output['scores'].tolist()\n",
    "\n",
    "              t_boxes = targets['boxes'].tolist()\n",
    "              t_labels = targets['labels'].tolist()\n",
    "\n",
    "              #select the first 35 returned boxes only\n",
    "              boxes = boxes[0:35]\n",
    "              labels = labels[0:35]\n",
    "              score = score[0:35]\n",
    "\n",
    "              #average score\n",
    "              avg_scr = sum(score) / len(score)\n",
    "              if avg_score == 0:\n",
    "                avg_score = avg_scr\n",
    "              else:\n",
    "                avg_score = (avg_score + avg_scr) / 2\n",
    "\n",
    "              #check bbox and classification accuracy\n",
    "              for x in range(len(labels)):\n",
    "                pred_box = boxes[x]\n",
    "                pred_label = labels[x]\n",
    "\n",
    "                possible_bounding_boxes += 1\n",
    "\n",
    "                #find closest matching box if any\n",
    "                for k in range(len(t_labels)):\n",
    "                  t_box = t_boxes[k]\n",
    "                  area_of_overlap = area_of_intersection(pred_box, t_box)\n",
    "                  area_of_truth = (t_box[2] - t_box[0]) * (t_box[3] - t_box[1])\n",
    "                  percentage_overlap = area_of_overlap / area_of_truth\n",
    "                  if percentage_overlap >= overlap_threshold:\n",
    "                    #bounding box match\n",
    "                    correct_bounding_box += 1\n",
    "                    possible_labels += 1\n",
    "                    #check label\n",
    "                    if pred_label == t_labels[k]:\n",
    "                      correct_labels +=1\n",
    "                    break\n",
    "\n",
    "        bounding_perf = correct_bounding_boxes / possible_bounding_boxes\n",
    "        label_perf = correct_labels / possible_labels\n",
    "\n",
    "        print(f'Performance at {epochs}=> BBOX: {bounding_perf}, LABEL: {label_perf}, AVG CONFIDENCE: {avg_score}')\n",
    "\n",
    "        return (bounding_perf, label_perf, avg_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcnn test\n",
    "learning_rate = 0.005\n",
    "# for num_epochs in range(,51, 10):\n",
    "num_epochs = 10\n",
    "overlap_threshold = 0.90\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(progress=True, num_classes=48)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr  = learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.001)\n",
    "\n",
    "bbox_perf, label_perf, conf = test_and_evaluate(model, device, optimizer, scheduler, num_epochs, batch_size, training_loader, testing_loader, testing_dataset, overlap_threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
